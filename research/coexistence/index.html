<!DOCTYPE html>
<html lang="en">

  <head>
    
    
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0TBNKXSNZH"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0TBNKXSNZH');
</script>


<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Rafal Kucharski Lab


  | COeXISTENCE

</title>
<meta name="description" content="ERC Starting Grant on COeXISTENCE between humans and machines in urban mobility">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.xyz/repo/jwarby/jekyll-pygments-themes/master/autumn.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🙌</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="/assets/css/rk.css">
<link rel="canonical" href="https://rafalkucharskipk.github.io/research/coexistence/">

<!-- Magnific Popup core CSS file -->
<link rel="stylesheet" href="/assets/css/magnific-popup.css">


<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>





    <style>
      .seminars,
      .justified {
        text-align: justify;
      }
    </style>
  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://rafalkucharskipk.github.io/">
       Rafal Kucharski Lab
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item dropdown ">
              <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                projects
                
              </a>
              <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
              
              
                <a class="dropdown-item" href="/research/coexistence/">COeXISTENCE</a>
              
              
              
                <div class="dropdown-divider"></div>
              
              
              
                <a class="dropdown-item" href="/research/g_1_OPUS/">OPUS</a>
              
              
              
                <div class="dropdown-divider"></div>
              
              
              
                <a class="dropdown-item" href="/research/SUM/">SUM</a>
              
              
              
                <div class="dropdown-divider"></div>
              
              
              
                <a class="dropdown-item" href="/research">others</a>
              
              
              </div>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/group/">
                people
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/papers/">
                papers
                
              </a>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/posts/index.html">
                news
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/seminars/index.html">
                seminars
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="justified">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">COeXISTENCE</h1>
    <p class="post-description">ERC Starting Grant on COeXISTENCE between humans and machines in urban mobility</p>
  </header>

  <article>
    <p><img width="350" src="/./assets/img/logo_COeXISTENCE.jpeg" alt="drawing" class="responsive-logo"><img src="/./assets/img/LOGO-ERC.jpg" alt="drawing" height="100"></p>

<blockquote>
  <p>What will be the future of our cities with autonomous vehicles, using any kind of ML algorithms to make collective routing decisions? <strong>Let’s see what we know so far</strong></p>
</blockquote>

<p>We pioneer the very specific problem that our cities may face in future, when autonomous vehicles are efficiently navigating across our cities. 
They will, individually or collectively, make routing decisions. The same decisions which are now daily made by millions of human drivers worldwide and result in traffic jams and complex congestion patterns, will be delegated to machines.
What will it change? <strong>Let’s see</strong></p>

<h3 id="-this-is-what-we-know-so-far-from-our-research">📚 This is what we know so far from our research:</h3>

<p>(click for short overview)</p>
<ul>
  <li>
<span style="color:red">Alarming:</span>
    <ul>
      <li><a href="#fleet-strategy-controls-the-overall-system-performance">Fleet strategy controls the overall system performance</a></li>
      <li><a href="#cavs-may-form-exclusive-clubs">CAVs may form exclusive clubs</a></li>
      <li><a href="#creating-travel-time-oscillations-is-a-good-strategy-to-maximise-fleet-market-share">Creating travel time oscillations is a good strategy to maximise fleet market share</a></li>
      <li><a href="#state-of-the-art-rl-algorithms-fail-even-on-trivial-routing-tasks">State-of-the-art RL algorithms fail even on trivial routing tasks.</a></li>
    </ul>
  </li>
  <li>
<span style="color:green">Promising:</span>
    <ul>
      <li><a href="#traffic-assignment-can-be-both-nash-optimal-and-equilibrated-with-cavs">Traffic assignment can be both Nash optimal and equilibrated with CAVs</a></li>
      <li><a href="#it-is-better-to-be-a-good-socially-aware-cav-then-selfish">It is better to be a good, socially aware CAV then selfish</a></li>
      <li><a href="#unsocial-fleet-behaviours-can-be-detected">Unsocial fleet behaviours can be detected.</a></li>
      <li><a href="#ml-community-shall-compete-to-develop-efficient-algorithms">ML community can compete to develop efficient algorithms</a></li>
    </ul>
  </li>
  <li>Tools and software we created to answer those questions
    <ul>
      <li>
<a href="how-to-simulate-such-future-system">RouteRL</a> Multi-Agent Reinforcement Learning framework is central framework, along with others available on this public repositories <a href="https://github.com/COeXISTENCE-PROJECT" target="_blank" rel="noopener noreferrer">COeXISTENCE Project GitHub</a>
</li>
    </ul>
  </li>
</ul>

<hr>

<h4 id="problem-formulation-and-overall-methodology">Problem formulation and overall methodology:</h4>

<p align="center">
  <img src="/./assets/img/scirep.jpg" alt="drawing" width="500"> 
</p>

<p>See the brief problem overview <a href="https://raw.githubusercontent.com/RafalKucharskiPK/rafalkucharskipk.github.io/master/assets/pdf/flyer.pdf" target="_blank" rel="noopener noreferrer">here</a> and a longer kick-off talk  <a href="https://raw.githubusercontent.com/RafalKucharskiPK/rafalkucharskipk.github.io/master/assets/pdf/Wyklad_ERC.pdf" target="_blank" rel="noopener noreferrer">presentation</a>.</p>

<blockquote>
  <p><strong>Disclaimer</strong> <span style="color:red"> we do not address the autonomous driving itself and operations. We assume AVs can well navigate in our cities: start, drive, cruise, detect objects, stop, obey traffic rules and park. </span> Dozens of excellent research teams already contribute to this, we adress the follow-up problem: <em>What when CAVs will start making our decisions, e.g. routing decisions</em>. We anegdotically compare it to the case of toddler who learns how to walk, but the true problems come with teenagers who may start to decide (e.g. on colour of hair, tattoos, carreer, etc).</p>

  <hr>
</blockquote>

<h1 id="findings">Findings:</h1>

<h4 id="cavs-may-form-exclusive-clubs">CAVs may form exclusive clubs</h4>

<blockquote>
  <p>We show that <a href="https://arxiv.org/pdf/2510.12862" target="_blank" rel="noopener noreferrer">Equilibria in routing games with connected autonomous vehicles will not be strong, as exclusive clubs may form</a></p>
</blockquote>

<p>CAVs will be able to break from Nash equilibrium and form a coalitions, collaborating to devise a joint routing pattern, allowing them to arrive faster. However, with limited resources, i.e. the capacity in road networks, a
group arriving faster will gain at the expense of others, arriving later. Also, not everyone can be invited to join the group as remains efficient only until
some point. They will be exclusive, and ,as other exclusive goods, unavailable to masses and limited to upper classes only. Threatening equity of using public space of our cities.</p>

<p align="center">
<img width="350" src="/./assets/img/overview.png" alt="drawing" class="responsive-logo">
</p>

<h4 id="creating-travel-time-oscillations-is-a-good-strategy-to-maximise-fleet-market-share">Creating travel time oscillations is a good strategy to maximise fleet market share</h4>

<blockquote>
  <p>We demonstrate the fleet may intentionally bring choas to our cities to maximise market share <a href="arxiv">here</a></p>
</blockquote>

<p>What is the optimal strategy to maximise market share and convince most drivers to join own fleet? Surprisingly, <strong>bringing chaos</strong> may be quite effective. Controlled oscillations of traffic flows, predictable by fleet operator, surprising to humans may be frustrating enough to convince others to abandon human driving and join some fleet. Individually tailored offers (just like Uber, Amazon or Ryanair) leveraging on our behavioural traits may be exploitable as well, and our low expectations (due to low budget or high urgency) may enable network-wide strange assignment plans, ultimately leading to increasing market shares. Those are initial results from monopoly, where single operator competes with humans, strach pomyśleć co będzie when competing fleets launch aggressive campaigns deployed at our cities.</p>

<p align="center">
<img width="350" src="/./assets/img/oscillations.jpg" alt="drawing">
</p>

<h4 id="traffic-assignment-can-be-both-nash-optimal-and-equilibrated-with-cavs">Traffic assignment can be both Nash optimal and equilibrated with CAVs</h4>

<blockquote>
  <p>New concept of Wardrop Cyclical Equiblibruim is both optimal and fair for CAVs as we show <a href="https://arxiv.org/pdf/2507.19675" target="_blank" rel="noopener noreferrer">here</a></p>
</blockquote>

<p>Connected and Autonomous Vehicles (CAVs) open the possibility for centralised routing with full compliance, making System Optimal traffic assignment attainable. However, as System Optimum makes some drivers better off than others, voluntary acceptance seems dubious. To overcome this issue, we propose a new concept of Wardropian cycles, which, in contrast to previous utopian visions, makes the assignment fair on top of being optimal, which amounts to satisfaction of both Wardrop’s principles. Such cycles, represented as sequences of permutations to the daily assignment matrices, always exist and equalise, after a limited number of days, average travel times among travellers (like in User Equilibrium) while preserving everyday optimality of path flows (like in System Optimum). In Barcelona, 670 vehicle-hours of Price-of-Anarchy are eliminated using cycles with a median length of 11 days-though 5% of cycles exceed 90 days.</p>

<p align="center">
<img width="350" src="/./assets/img/grafika_latest.png" alt="drawing">
</p>

<h4 id="how-to-simulate-such-future-system">How to simulate such future system?</h4>

<blockquote>
  <p>We created <a href="https://github.com/COeXISTENCE-PROJECT/RouteRL" target="_blank" rel="noopener noreferrer">RouteRL</a> Multi-Agent Reinforcement Learning framework for modeling and simulating the collective route choices of humans and autonomous vehicles - <a href="https://doi.org/10.1016/j.softx.2025.102279" target="_blank" rel="noopener noreferrer">SoftwareX</a></p>
</blockquote>
<p align="center">
  <img src="https://github.com/COeXISTENCE-PROJECT/RouteRL/raw/main/docs/_static/logo.png" alt="drawing" width="150"> 
</p>

<p>RouteRL is a novel framework that integrates multi-agent reinforcement learning (MARL) with a microscopic traffic simulation for the development of efficient collective route choice strategies for autonomous vehicles (AVs). The proposed framework models the daily urban route choices of driver agents of two types: human drivers, emulated using behavioral route choice models, and AVs, modeled as MARL agents optimizing their policies for a predefined objective. RouteRL aims to advance research in MARL, transport modeling, and human–AI interaction for transportation applications.</p>

<p align="center">
<img src="/./assets/img/RouteRL.jpg" width="350">
</p>

<h4 id="state-of-the-art-rl-algorithms-fail-even-on-trivial-routing-tasks">State-of-the-art RL algorithms fail even on trivial routing tasks.</h4>

<blockquote>
  <p>Only few of SOTA Reinforcement Learning algorithms managed to find optimal routing strategy in a trivial case with 10 AVs and two-routes as we report in this <a href="https://arxiv.org/pdf/2502.13188" target="_blank" rel="noopener noreferrer">paper</a></p>
</blockquote>

<p>Autonomous vehicles (AVs), possibly using Multi-Agent Reinforcement Learning (MARL) for simultaneous route optimization, may destabilize traffic networks, with human drivers potentially experiencing longer travel times. We study this interaction by simulating human drivers and AVs. Our experiments with standard MARL algorithms reveal that, both in simplified and complex networks, policies often fail to converge to an optimal solution or require long training periods. This problem is amplified by the fact that we cannot rely entirely on simulated training, as there are no accurate models of human routing behavior. At the same time, real-world training in cities risks destabilizing urban traffic systems, increasing externalities, such as CO2 emissions, and introducing non-stationarity as human drivers will adapt unpredictably to AV behaviors.</p>

<p align="center">
<img width="350" src="/./assets/img/storyline.png">
</p>

<h4 id="ml-community-shall-compete-to-develop-efficient-algorithms">ML community shall compete to develop efficient algorithms</h4>

<blockquote>
  <p>We introduced <a href="https://github.com/COeXISTENCE-PROJECT/URB" target="_blank" rel="noopener noreferrer">URB</a> an Urban Routing Benchmark for MARL algorithms on the fleet routing tasks - <a href="https://arxiv.org/abs/2505.17734" target="_blank" rel="noopener noreferrer">NIPS 2025</a></p>
</blockquote>
<p align="center">
   <img src="https://github.com/COeXISTENCE-PROJECT/URB/blob/main/docs/urb.png" alt="drawing" width="150"> 
</p>

<p><code class="language-plaintext highlighter-rouge">URB</code> is a comprehensive benchmarking environment that unifies evaluation across <strong>29 real-world traffic networks paired with realistic demand patterns</strong>. <code class="language-plaintext highlighter-rouge">URB</code> comes with a catalog of <strong>predefined tasks, multi-agent RL (MARL) algorithm implementations, three baseline methods, ten domain-specific performance metrics, and a modular configuration scheme</strong>.</p>

<p>Through this broad experimental scheme, <code class="language-plaintext highlighter-rouge">URB</code> aims to:</p>

<ol>
  <li>Identify which state-of-the-art algorithms outperform others in this class of tasks,</li>
  <li>Drive competition for future algorithmic improvements, and</li>
  <li>Clarify the impact of collective CAV routing on congestion, emissions, and sustainability in future cities, equipping policymakers with solid arguments for CAV regulations.</li>
</ol>

<p align="center">
<img src="/./assets/img/urb_overview.png" width="350">
</p>

<h4 id="it-is-better-to-be-a-good-socially-aware-cav-then-selfish">It is better to be a good, socially aware CAV then selfish</h4>

<blockquote>
  <p>Autonomous vehicles need social awareness to find optima in multi-agent reinforcement learning routing games as we show <a href="https://arxiv.org/pdf/2510.11410" target="_blank" rel="noopener noreferrer">here</a></p>
</blockquote>

<p>Previous work has shown that when multiple selfish Autonomous Vehicles (AVs) are introduced to future cities and start learning optimal routing strategies using Multi-Agent Reinforcement Learning (MARL), they may destabilize traffic systems, as they would require a significant amount of time to converge to the optimal solution, equivalent to years of real-world commuting.
We demonstrate that moving beyond the selfish component in the reward significantly relieves this issue. If each AV, apart from minimizing its own travel time, aims to reduce its impact on the system, this will be beneficial not only for the system-wide performance but also for each individual player in this routing game.
By introducing an intrinsic reward signal based on the marginal cost matrix, we significantly reduce training time and achieve convergence more reliably. 
Our results optimistically indicate that social awareness (i.e., including marginal costs in routing decisions) improves both the system-wide and individual performance of future urban systems with AVs.</p>

<p align="center">
<img src="/./assets/img/marginal.png" width="350">
</p>

<h4 id="fleet-strategy-controls-the-overall-system-performance">Fleet strategy controls the overall system performance</h4>

<blockquote>
  <p>In this <a href="https://www.nature.com/articles/s41598-025-90783-w" target="_blank" rel="noopener noreferrer">study</a> we show that the strategy CAVs are allowed to adopt may result in human drivers either benefitting or being systematically disadvantaged and urban networks becoming either more or less optimal.</p>
</blockquote>

<p>Studying the simplest on the two-route bottleneck macroscopic network we discover that:</p>

<ul>
  <li>The choices of CAVs that replace a given share of HDVs differ significantly from the choices of the remaining HDVs.</li>
  <li>In different scenarios the average travel time of both HDVs and CAVs may increase or decrease.</li>
  <li>If the fleet of CAVs applies the selfish strategy, it may improve its collective travel time at a cost to human drivers when the share of CAVs is small.</li>
  <li>For a large share of CAVs, the selfish or social strategies of CAVs may result in improvement of travel times for all the drivers. This, however, comes at a price of reduced equity.</li>
  <li>Human driver populations with low perception bias may be less prone to exploitation by intelligent fleets of CAVs than more diverse and less optimal populations.</li>
  <li>Heavily congested systems, where the choices of HDVs and CAVs tend to be similar, may be less susceptible to exploitation by CAVs. Contrariwise, uncongested networks could be easily exploited by machines.</li>
</ul>

<p align="center">
<img src="/./assets/img/scirep2.jpg" width="350">
</p>

<h4 id="unsocial-fleet-behaviours-can-be-detected">Unsocial fleet behaviours can be detected.</h4>

<blockquote>
  <p>It is possible to identify the individual vehicles of a coordinated fleet if they are antisocial as we prove in this <a href="https://arxiv.org/pdf/2506.22966" target="_blank" rel="noopener noreferrer">paper</a></p>
</blockquote>

<p>Detection of collectively routing fleets of vehicles in future urban systems may become important
for the management of traffic, as such routing may destabilize urban networks leading to deterioration of
driving conditions. To address this issue, in this we address two related problems:</p>
<ul>
  <li>Is it possible to determine the flow of fleet vehicles on all routes given the fleet size and behaviour as well as the combined total flow of fleet and non-fleet vehicles on every route?</li>
</ul>

<p>We prove that the answer is ’yes’ for myopic fleet strategies which are more ’selfish’ than ’altruistic’, and
’no’ otherwise.</p>

<ul>
  <li>Is it possible to identify the individual vehicles of a coordinated fleet within a reasonable time horizon based
on observation of every vehicle route choice every day?</li>
</ul>

<p>Our finginds indicate that the answer is likely to be ’yes’ for evil fleet objectives and ’no’ for pro-social fleet objectives.</p>

<p align="center">
<img src="/./assets/img/detect.jpg" width="350">
</p>

<hr>

<!---
We want to understand the future of Urban Mobility and foresee what happens when our cities are shared with autonomous, intelligent robots - competing with us for limited resources. 
* We demonstrated the novel phenomena on simple topologies [here](https://www.nature.com/articles/s41598-025-90783-w)
* We created the dedicated MARL environment for our experiments [paper](https://arxiv.org/pdf/2502.20065) and repository on [GitHub](https://github.com/COeXISTENCE-PROJECT/RouteRL)
* We have some preliminary results from [EWRL](https://openreview.net/pdf?id=88zP8xh5D2)
* We identified issues with convergence and reported them [here](https://arxiv.org/pdf/2502.13188)

For updates and new contributions you may consult our [GitHub](https://github.com/COeXISTENCE-PROJECT) or follow us on social media. 

For collaborations, please contact us or simply start contributing on our repos.



. We create virtual environments where individual agents compete to arrive faster, more reliably and cheaper at their destinations.  Human agents are simulated with detailed behavioural models, estimated and calibrated on the field data to reproduce how we behave and adapt in the cities. In the same environment the deep learning agents try the same - they  use deep reinforcement learning to maximise their rewards. This creates a harsh competition in which machines have upper-hands strong enough to beat us. 



*COeXISTENCE* is a broad and deep experiment in virtual environment on future cities, aimed to discover the new phenomena and propose the new solutions. 
It spans between fields as diverse as:

* game theory;
* deep reinforcement learning;
* complex social systems;
* sustainability;
* urban mobility;
* agent based modelling;
* discrete choice theory.
--->

<h3 id="about-us">About us</h3>

<hr>

<h3 id="vacancies">Vacancies</h3>

<p>We are always collaborators hungry, free to reach us out to understand more about opportunities at <strong>coexistence@uj.edu.pl</strong></p>

<hr>

<p align="center">
<img src="/./assets/img/LOGO-ERC.jpg" alt="drawing" height="220"><img src="/./assets/img/logo_kwadrat.jpg" alt="drawing" height="220">
</p>

<p><sub><strong>Disclaimer</strong>: Funded by the European Union. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or European Research Council Executive Agency (ERCEA). Neither the European Union nor the granting authority can be held responsible for them.</sub></p>

<p><sub><strong>Funding acknowledgement</strong>: This project has received funding from the European Research Council (ERC) under the European Union’s Horizon Europe research and innovation programme  (grant agreement No 101075838).</sub></p>


  </article>
	
      <div class="publications">
  <h2>Publications linked to the project</h2>
   <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="akman2025urb" class="col-sm-8">
    
      <div class="title">URB - Urban Routing Benchmark for RL-equipped Connected Autonomous Vehicles</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Akman, Ahmet Onur,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Psarou, Anastasia,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hoffmann, Michał,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gorczyca, Łukasz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kowalski, Łukasz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gora, Paweł,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jamróz, Grzegorz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kucharski, Rafał
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2505.17734</em>
      
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://doi.org/10.48550/arXiv.2505.17734" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Connected Autonomous Vehicles (CAVs) promise to reduce congestion in future urban networks, potentially by optimizing their routing decisions. Unlike for human drivers, these decisions can be made with collective, data-driven policies, developed by machine learning algorithms. Reinforcement learning (RL) can facilitate the development of such collective routing strategies, yet standardized and realistic benchmarks are missing. To that end, we present \our: Urban Routing Benchmark for RL-equipped Connected Autonomous Vehicles. \our is a comprehensive benchmarking environment that unifies evaluation across 29 real-world traffic networks paired with realistic demand patterns. \our comes with a catalog of predefined tasks, four state-of-the-art multi-agent RL (MARL) algorithm implementations, three baseline methods, domain-specific performance metrics, and a modular configuration scheme. Our results suggest that, despite the lengthy and costly training, state-of-the-art MARL algorithms rarely outperformed humans. Experimental results reported in this paper initiate the first leaderboard for MARL in large-scale urban routing optimization and reveal that current approaches struggle to scale, emphasizing the urgent need for advancements in this domain.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">SoftwareX</abbr>
    
  
  </div>

  <div id="akman2025routerl" class="col-sm-8">
    
      <div class="title">RouteRL: Multi-agent reinforcement learning framework for urban route choice with autonomous vehicles</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Akman, Ahmet Onur,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Psarou, Anastasia,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gorczyca, Łukasz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Varga, Zoltán György,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jamróz, Grzegorz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kucharski, Rafał
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>SoftwareX</em>
      
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://www.sciencedirect.com/science/article/pii/S2352711025002468?via%3Dihub" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>RouteRL is a novel framework that integrates multi-agent reinforcement learning (MARL) with a microscopic traffic simulation for the development of efficient collective route choice strategies for autonomous vehicles (AVs). The proposed framework models the daily urban route choices of driver agents of two types: human drivers, emulated using behavioral route choice models, and AVs, modeled as MARL agents optimizing their policies for a predefined objective. RouteRL aims to advance research in MARL, transport modeling, and human–AI interaction for transportation applications. This study presents a technical report on RouteRL, outlines its potential research contributions, and showcases its impact via illustrative examples. Initial findings show that human travel times could increase following the introduction of AVs in urban environments, highlighting the importance of future studies to support efficient urban mobility.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="psarou2025autonomous" class="col-sm-8">
    
      <div class="title">Autonomous Vehicles Using Multi-Agent Reinforcement Learning for Routing Decisions Can Harm Urban Traffic</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Psarou, Anastasia,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Akman, Ahmet Onur,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gorczyca, Łukasz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hoffmann, Michał,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Varga, Zoltán György,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jamróz, Grzegorz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kucharski, Rafał
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2502.13188</em>
      
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://www.arxiv.org/abs/2502.13188" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Autonomous vehicles (AVs) using Multi-Agent Reinforcement Learning (MARL) for simultaneous route optimization may destabilize traffic environments, with human drivers possibly experiencing longer travel times. We study this interaction by simulating human drivers and AVs. Our experiments with standard MARL algorithms reveal that, even in trivial cases, policies often fail to converge to an optimal solution or require long training periods. The problem is amplified by the fact that we cannot rely entirely on simulated training, as there are no accurate models of human routing behavior. At the same time, real-world training in cities risks destabilizing urban traffic systems, increasing externalities, such as CO2 emissions, and introducing non-stationarity as human drivers adapt unpredictably to AV behaviors. Centralization can improve convergence in some cases, however, it raises privacy concerns for the travelers’ destination data. In this position paper, we argue that future research must prioritize realistic benchmarks, cautious deployment strategies, and tools for monitoring and regulating AV routing behaviors to ensure sustainable and equitable urban mobility systems.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Sci. Rep.</abbr>
    
  
  </div>

  <div id="jamroz2025social" class="col-sm-8">
    
      <div class="title">Social implications of coexistence of CAVs and human drivers in the context of route choice</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Jamróz, Grzegorz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Akman, Ahmet Onur,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Psarou, Anastasia,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Varga, Zoltán György,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kucharski, Rafał
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Scientific Reports</em>
      
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://doi.org/10.1038/s41598-025-90783-w" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Suppose in a stable urban traffic system populated only by human driven vehicles (HDVs), a given proportion (e.g. 10 %) is replaced by a fleet of Connected and Autonomous Vehicles (CAVs), which share information and pursue a collective goal. Suppose these vehicles are centrally coordinated and differ from HDVs only by their collective capacities allowing them to make more efficient routing decisions before the travel on a given day begins. Suppose there is a choice between two routes and every day each driver makes a decision which route to take. Human drivers maximize their utility. CAVs might optimize different goals, such as the total travel time of the fleet. We show that in this plausible futuristic setting, the strategy CAVs are allowed to adopt may result in human drivers either benefitting or being systematically disadvantaged and urban networks becoming more or less optimal. Consequently, some regulatory measures might become indispensable.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>
</div>

    
</div>

      </div>
    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    © Copyright 2025 Rafal  Kucharski.
    
    
    
    Last updated: October 24, 2025.
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- jQuery -->
<script src="/assets/js/jquery.magnific-popup.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>


  





</html>
