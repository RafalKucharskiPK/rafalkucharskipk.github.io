<!DOCTYPE html>
<html lang="en">

  <head>
    
    
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0TBNKXSNZH"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0TBNKXSNZH');
</script>


<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Rafal Kucharski Lab


  | Onur Akman

</title>
<meta name="description" content="PhD student in dynamics of two-sided mobility markets">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.xyz/repo/jwarby/jekyll-pygments-themes/master/autumn.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üôå</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="/assets/css/rk.css">
<link rel="canonical" href="https://rafalkucharskipk.github.io/research/onur_akman/">

<!-- Magnific Popup core CSS file -->
<link rel="stylesheet" href="/assets/css/magnific-popup.css">


<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>





    <style>
      .seminars,
      .justified {
        text-align: justify;
      }
    </style>
  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://rafalkucharskipk.github.io/">
       Rafal Kucharski Lab
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item dropdown ">
              <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                projects
                
              </a>
              <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
              
              
                <div class="dropdown-divider"></div>
              
              
              
                <a class="dropdown-item" href="/research/coexistence/">COeXISTENCE</a>
              
              
              
                <div class="dropdown-divider"></div>
              
              
              
                <a class="dropdown-item" href="/research/g_1_OPUS/">OPUS</a>
              
              
              
                <div class="dropdown-divider"></div>
              
              
              
                <a class="dropdown-item" href="/research/SUM/">SUM</a>
              
              
              
                <div class="dropdown-divider"></div>
              
              
              
                <a class="dropdown-item" href="/research">others</a>
              
              
              </div>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/group/">
                people
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/papers/">
                papers
                
              </a>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/posts/index.html">
                news
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/seminars/index.html">
                seminars
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="justified">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Onur Akman</h1>
   
  </header>

	<article>
		<div class="profile float-right">
			 
        <picture>
  
    <source srcset="/assets/resized/OA-renew-480x721.jpg 480w" media="(max-width: 480px)">
  
    <source srcset="/assets/resized/OA-renew-800x1201.jpg 800w" media="(max-width: 800px)">
  
    <source srcset="/assets/resized/OA-renew-1400x2102.jpg 1400w" media="(max-width: 1400px)">
  

  <img src="/assets/resized/OA-renew-1400x2102.jpg" srcset="
      
        /assets/resized/OA-renew-480x721.jpg 480w, 
      
        /assets/resized/OA-renew-800x1201.jpg 800w, 
      
        /assets/resized/OA-renew-1400x2102.jpg 1400w
      
    " sizes="(max-width: 768px) 100vw, 768px" alt="project thumbnail" loading="lazy" decoding="async">
</source></source></source></picture>

      
			
			<div class="address">
				<p>
					
						  					  			  
					  
						    
							
							
							<br><a href="https://github.com/aonurakman" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i> GH_Onur Akman</a>
							
							
							
							
							
							<br><a href="https://scholar.google.com/citations?user=MUVshfEAAAAJ&amp;hl=tr" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i> scholar_OA</a>
							
							
							
							<br><a href="https://www.instagram.com/aonurakman" target="_blank" rel="noopener noreferrer"><i class="fas fa-envelope"></i> insta_Akman</a>
							
							
							
							<br><a href="https://www.linkedin.com/in/aonurakman" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i> linkedin_OA</a>
							
						
							
							<br><a href="https://orcid.org/0009-0006-4461-5025" target="_blank" rel="noopener noreferrer"><i class="ai ai-orcid"></i> 0009-0006-4461-5025</a>
							
							
							
							
							
							<br><a href="https://twitter.com/aonurakman" target="_blank" rel="noopener noreferrer"><i class="fab fa-twitter"></i> x_Onur Akman</a>
							
							
							
				</p>
				
        </div>
      
    </div>
    <p>Hello there! My name is Onur, I‚Äôm a Computer Engineer with a specialization in Artificial Intelligence. I am from a lovely city called Eski≈üehir in T√ºrkiye. My journey in this field began at Yƒ±ldƒ±z Technical University in Istanbul, where I earned my Bachelor‚Äôs degree in Computer Engineering. For my thesis, I worked on an exciting medical AI project that leveraged computer vision. After completing my Bachelor‚Äôs degree, I spent two years in Italy, pursuing a master‚Äôs degree in Computer Engineering from the University of Padova.</p>

<p>During my time at UNIPD, I specialized in AI &amp; Robotics and focused my research on Natural Language Processing. My thesis involved proposing a novel static word embedding model. Outside of work, I am passionate about traveling and learning about different culinary practices. Currently, I am thrilled to be a member of the COeXISTENCE team here at Jagiellonian University in the beautiful city of Krak√≥w. Here I continue my learning journey and contribute to building a deeper understanding of the interaction between humans and autonomous agents in future traffic environments.</p>

<p>In today‚Äôs fast-changing world of AI, the interactions of various subfields are not just beneficial, but essential. Consequently, I believe that every AI enthusiast is responsible for staying up-to-date with every other subfield, regardless of the specific professional focus. With this mindset, my previous research interests and projects span deep learning, classifiers and regressors, computer vision, clustering algorithms, reinforcement learning, and natural language processing. Also, I have experience with mobile development and The Robotic Operating System. Currently, I am continuing my studies on reinforcement learning. I am exploring innovative methods to model learning in simulations that mirror natural learning processes, aiming for accuracy and efficiency.</p>

    
    
      <div class="publications">
  <h2>List of main publications and preprints</h2>
   <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="akman2025urb" class="col-sm-8">
    
      <div class="title">URB - Urban Routing Benchmark for RL-equipped Connected Autonomous Vehicles</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Akman, Ahmet Onur,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Psarou, Anastasia,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hoffmann, Micha≈Ç,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gorczyca, ≈Åukasz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kowalski, ≈Åukasz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gora, Pawe≈Ç,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jamr√≥z, Grzegorz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kucharski, Rafa≈Ç
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2505.17734</em>
      
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://doi.org/10.48550/arXiv.2505.17734" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Connected Autonomous Vehicles (CAVs) promise to reduce congestion in future urban networks, potentially by optimizing their routing decisions. Unlike for human drivers, these decisions can be made with collective, data-driven policies, developed by machine learning algorithms. Reinforcement learning (RL) can facilitate the development of such collective routing strategies, yet standardized and realistic benchmarks are missing. To that end, we present \our: Urban Routing Benchmark for RL-equipped Connected Autonomous Vehicles. \our is a comprehensive benchmarking environment that unifies evaluation across 29 real-world traffic networks paired with realistic demand patterns. \our comes with a catalog of predefined tasks, four state-of-the-art multi-agent RL (MARL) algorithm implementations, three baseline methods, domain-specific performance metrics, and a modular configuration scheme. Our results suggest that, despite the lengthy and costly training, state-of-the-art MARL algorithms rarely outperformed humans. Experimental results reported in this paper initiate the first leaderboard for MARL in large-scale urban routing optimization and reveal that current approaches struggle to scale, emphasizing the urgent need for advancements in this domain.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">SoftwareX</abbr>
    
  
  </div>

  <div id="akman2025routerl" class="col-sm-8">
    
      <div class="title">RouteRL: Multi-agent reinforcement learning framework for urban route choice with autonomous vehicles</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Akman, Ahmet Onur,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Psarou, Anastasia,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gorczyca, ≈Åukasz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Varga, Zolt√°n Gy√∂rgy,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jamr√≥z, Grzegorz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kucharski, Rafa≈Ç
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>SoftwareX</em>
      
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://www.sciencedirect.com/science/article/pii/S2352711025002468?via%3Dihub" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>RouteRL is a novel framework that integrates multi-agent reinforcement learning (MARL) with a microscopic traffic simulation for the development of efficient collective route choice strategies for autonomous vehicles (AVs). The proposed framework models the daily urban route choices of driver agents of two types: human drivers, emulated using behavioral route choice models, and AVs, modeled as MARL agents optimizing their policies for a predefined objective. RouteRL aims to advance research in MARL, transport modeling, and human‚ÄìAI interaction for transportation applications. This study presents a technical report on RouteRL, outlines its potential research contributions, and showcases its impact via illustrative examples. Initial findings show that human travel times could increase following the introduction of AVs in urban environments, highlighting the importance of future studies to support efficient urban mobility.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Sci. Rep.</abbr>
    
  
  </div>

  <div id="jamroz2025social" class="col-sm-8">
    
      <div class="title">Social implications of coexistence of CAVs and human drivers in the context of route choice</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Jamr√≥z, Grzegorz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Akman, Ahmet Onur,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Psarou, Anastasia,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Varga, Zolt√°n Gy√∂rgy,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kucharski, Rafa≈Ç
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Scientific Reports</em>
      
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://doi.org/10.1038/s41598-025-90783-w" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Suppose in a stable urban traffic system populated only by human driven vehicles (HDVs), a given proportion (e.g. 10 %) is replaced by a fleet of Connected and Autonomous Vehicles (CAVs), which share information and pursue a collective goal. Suppose these vehicles are centrally coordinated and differ from HDVs only by their collective capacities allowing them to make more efficient routing decisions before the travel on a given day begins. Suppose there is a choice between two routes and every day each driver makes a decision which route to take. Human drivers maximize their utility. CAVs might optimize different goals, such as the total travel time of the fleet. We show that in this plausible futuristic setting, the strategy CAVs are allowed to adopt may result in human drivers either benefitting or being systematically disadvantaged and urban networks becoming more or less optimal. Consequently, some regulatory measures might become indispensable.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="akman2025impact" class="col-sm-8">
    
      <div class="title">Impact of collective behaviors of autonomous vehicles on urban traffic dynamics: A multi-agent reinforcement learning approach</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Akman, Ahmet Onur,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Psarou, Anastasia,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Varga, Zolt√°n Gy√∂rgy,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jamr√≥z, Grzegorz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kucharski, Rafa≈Ç
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2509.22216</em>
      
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://arxiv.org/abs/2509.22216" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This study examines the potential impact of reinforcement learning (RL)-enabled autonomous vehicles (AV) on urban traffic flow in a mixed traffic environment. We focus on a simplified day-to-day route choice problem in a multi-agent setting. We consider a city network where human drivers travel through their chosen routes to reach their destinations in minimum travel time. Then, we convert one-third of the population into AVs, which are RL agents employing Deep Q-learning algorithm. We define a set of optimization targets, or as we call them behaviors, namely selfish, collaborative, competitive, social, altruistic, and malicious. We impose a selected behavior on AVs through their rewards. We run our simulations using our in-house developed RL framework PARCOUR. Our simulations reveal that AVs optimize their travel times by up to 5%, with varying impacts on human drivers‚Äô travel times depending on the AV behavior. In all cases where AVs adopt a self-serving behavior, they achieve shorter travel times than human drivers. Our findings highlight the complexity differences in learning tasks of each target behavior. We demonstrate that the multi-agent RL setting is applicable for collective routing on traffic networks, though their impact on coexisting parties greatly varies with the behaviors adopted.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">arXiv</abbr>
    
  
  </div>

  <div id="psarou2025autonomout" class="col-sm-8">
    
      <div class="title">Autonomous Vehicles Using Multi-Agent Reinforcement Learning for Routing Decisions Can Harm Urban Traffic</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Psarou, Anastasia,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Akman, Ahmet Onur,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Gorczyca, ≈Åukasz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hoffmann, Micha≈Ç,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Varga, Zolt√°n Gy√∂rgy,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jamr√≥z, Grzegorz,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kucharski, Rafa≈Ç
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2502.13188</em>
      
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://www.arxiv.org/abs/2502.13188" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Autonomous vehicles (AVs) using Multi-Agent Reinforcement Learning (MARL) for simultaneous route optimization may destabilize traffic environments, with human drivers possibly experiencing longer travel times. We study this interaction by simulating human drivers and AVs. Our experiments with standard MARL algorithms reveal that, even in trivial cases, policies often fail to converge to an optimal solution or require long training periods. The problem is amplified by the fact that we cannot rely entirely on simulated training, as there are no accurate models of human routing behavior. At the same time, real-world training in cities risks destabilizing urban traffic systems, increasing externalities, such as CO2 emissions, and introducing non-stationarity as human drivers adapt unpredictably to AV behaviors. Centralization can improve convergence in some cases, however, it raises privacy concerns for the travelers‚Äô destination data. In this position paper, we argue that future research must prioritize realistic benchmarks, cautious deployment strategies, and tools for monitoring and regulating AV routing behaviors to ensure sustainable and equitable urban mobility systems.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>
</div>

    
  </article>

</div>

      </div>
    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    ¬© Copyright 2026 Rafal  Kucharski.
    
    
    
    Last updated: February 17, 2026.
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- jQuery -->
<script src="/assets/js/jquery.magnific-popup.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>


  





</html>
